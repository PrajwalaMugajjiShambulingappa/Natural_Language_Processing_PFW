# -*- coding: utf-8 -*-
"""Lab1-Assignment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DEPKznxNhtpHiwCaqjpNeR9udEF4rjv5
"""

#Upload the dataset
from google.colab import files
dataset = files.upload()

#Reading from the dataset
with open('Lab1-Dataset.txt') as f:
  dataset = f.read()

import re
def process_regex(dataset):

  # Regex implementation to replace British English Spellings for words that have an extra ‘u’ with American English spellings 
  text =  re.sub("\b([a-zA-Z]+)[^(?:y|p|s|t|h|f|\s)](our)(ed|ing|s|hood)*\b", '\1or\2', dataset)
  
  dataset_titles= {
     "Dr.": "Doctor",
      "Mr.": "Mister",
      "Ms.": "Miss",
      "Mrs." : "Misses"
      }

  # Replace titles with appropriate expansions of words
  for title, expansion in dataset_titles.items():
    txt = re.sub(title, expansion, text)
  
  #writing the above outputs to regex.txt file
  with open("regex.txt", "w") as f:
    f.write(txt)
  f.close()

process_regex(dataset)

with open('regex.txt', 'r') as f:
    processed_text = f.read()

# Normalization
def normalize_text(processed_text):
  
  # Finding and replacing all the uppercase words into lowercase
  for f in re.findall("([A-Z]+)", processed_text):
    processed_text = processed_text.replace(f, f.lower())

  # Replacing all the special characters, numbers and punctions 
  processed_text = re.sub(r'[^\w\s]', '', processed_text)

  # Removing reccusing words
  recurring_words = ['the','of','in','by','and', 'is', 'this', 'at', 'or', 'that', 'for', 'with', 'it', 'are', 'to']
  for word in recurring_words:
    processed_text = re.sub("\b" + word + "\b", " ",processed_text, flags=re.IGNORECASE)
  
  # Tokenizing the text
  processed_text = re.split("\W+", processed_text)
  
  # Writing the processed tokens into dictionary.txt file
  with open("dictionary.txt", "w") as f:
   for word in processed_text:
     f.write(word + "\n ")
  f.close()

normalize_text(processed_text)